## What technologies are used for this project?

This project is built with:

- Vite
- TypeScript
- React
- shadcn-ui
- Tailwind CSS

# ğŸ” BlindVision: Real-Time Object Detection for the Visually Impaired

BlindVision is an AI-powered wearable assistive system that helps visually impaired individuals navigate their surroundings safely and independently. It uses a real-time object detection model (YOLO) integrated with a text-to-speech (TTS) engine to describe nearby objects through audio feedback.

---

## ğŸ§  Features

- ğŸ¥ **Wearable Camera Input**: Captures real-time video stream.
- ğŸ§  **YOLOv5 Object Detection**: Detects common objects in the environment.
- ğŸ”Š **Text-to-Speech (TTS)**: Converts detected object names to speech output.
- âš¡ **Low Latency Processing**: Optimized for real-time feedback.
- ğŸ› ï¸ **Portable & Scalable**: Easily adaptable for different hardware setups (Jetson Nano, Raspberry Pi, or PC).

---

## ğŸ¯ Use Case

Designed for the visually impaired, BlindVision enables safer, more independent navigation by describing objects around the user in real-time, reducing reliance on others or static tools.


## ğŸš€ Getting Started

### Prerequisites

- Python 3.7+
- `pip install -r requirements.txt`
- Compatible webcam or wearable camera

### Clone the Repo

```bash
git clone https://github.com/Lavanya-1107/blindvision-assist.git
cd blindvision-assist


