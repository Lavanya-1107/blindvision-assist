## What technologies are used for this project?

This project is built with:

- Vite
- TypeScript
- React
- shadcn-ui
- Tailwind CSS

# 🔍 BlindVision: Real-Time Object Detection for the Visually Impaired

BlindVision is an AI-powered wearable assistive system that helps visually impaired individuals navigate their surroundings safely and independently. It uses a real-time object detection model (YOLO) integrated with a text-to-speech (TTS) engine to describe nearby objects through audio feedback.

---

## 🧠 Features

- 🎥 **Wearable Camera Input**: Captures real-time video stream.
- 🧠 **YOLOv5 Object Detection**: Detects common objects in the environment.
- 🔊 **Text-to-Speech (TTS)**: Converts detected object names to speech output.
- ⚡ **Low Latency Processing**: Optimized for real-time feedback.
- 🛠️ **Portable & Scalable**: Easily adaptable for different hardware setups (Jetson Nano, Raspberry Pi, or PC).

---

## 🎯 Use Case

Designed for the visually impaired, BlindVision enables safer, more independent navigation by describing objects around the user in real-time, reducing reliance on others or static tools.


## 🚀 Getting Started

### Prerequisites

- Python 3.7+
- `pip install -r requirements.txt`
- Compatible webcam or wearable camera

### Clone the Repo

```bash
git clone https://github.com/Lavanya-1107/blindvision-assist.git
cd blindvision-assist


